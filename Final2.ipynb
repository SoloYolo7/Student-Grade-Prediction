{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import optuna\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn\n",
    "import mlflow\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np \n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "import boto3\n",
    "from dotenv import load_dotenv  \n",
    "load_dotenv()\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://84.201.144.227:8000\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "sklearn.set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/student.csv').drop(columns=['number', 'Id'])\n",
    "df['Attendance'] = df['Attendance'].map({\"Always\": 3, \"Sometimes\": 2, \"Never\": 1, \"3\": None})\n",
    "df['Scholarship'] = df['Scholarship'].fillna(\"0%\").str.replace(\"%\", \"\").astype(int)\n",
    "\n",
    "grade_mapping = {\"Fail\": 0, \"FD\": 1, \"DD\": 2, \"DC\": 3, \"CC\": 4, \"CB\": 5, \"BB\": 6, \"BA\": 7, \"AA\": 8}\n",
    "df['Grade'] = df['Grade'].map(grade_mapping)\n",
    "\n",
    "X = df.drop(columns=['Grade'])\n",
    "y = df['Grade']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = pd.Series(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"valid_X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_pipe = Pipeline([\n",
    "    (\"SimpleImputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "    (\"OneHotEncoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    (\"SimpleImputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "    (\"OrdinalEncoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"PowerTransformer\", PowerTransformer())\n",
    "])\n",
    "\n",
    "ohe_list = ['Sex', 'High_School_Type', 'Transportation']\n",
    "ord_list = X.select_dtypes(include=\"object\").columns.drop(ohe_list)\n",
    "num_list = X.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ColumnTransformer([\n",
    "    (\"ord_pipe\", ord_pipe, ord_list),\n",
    "    (\"num_pipe\", num_pipe, num_list),\n",
    "    (\"ohe_pipe\", ohe_pipe, ohe_list)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-12 22:19:55,843] A new study created in memory with name: no-name-3dbc2a90-56d7-400a-bb15-9e4d1a7edd97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf7e4effa7a446e84ae9b47de010285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-12 22:24:44,029] Trial 0 finished with value: 0.19827586206896552 and parameters: {'model__estimator__n_estimators': 1000, 'model__estimator__max_depth': 8, 'model__estimator__learning_rate': 0.01919062588884188, 'model__estimator__subsample': 0.5553779148569076, 'model__estimator__colsample_bytree': 0.37215765007869583, 'model__estimator__gamma': 0.15523299260114232, 'model__estimator__reg_alpha': 0.0980949442350838}. Best is trial 0 with value: 0.19827586206896552.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры XGBoost: {'model__estimator__n_estimators': 1000, 'model__estimator__max_depth': 8, 'model__estimator__learning_rate': 0.01919062588884188, 'model__estimator__subsample': 0.5553779148569076, 'model__estimator__colsample_bytree': 0.37215765007869583, 'model__estimator__gamma': 0.15523299260114232, 'model__estimator__reg_alpha': 0.0980949442350838}\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"model__estimator__n_estimators\": trial.suggest_categorical(\"model__estimator__n_estimators\", [1000]),\n",
    "        \"model__estimator__max_depth\": trial.suggest_int(\"model__estimator__max_depth\", 6, 10),\n",
    "        \"model__estimator__learning_rate\": trial.suggest_float(\"model__estimator__learning_rate\", 0.001, 0.05),\n",
    "        \"model__estimator__subsample\": trial.suggest_float(\"model__estimator__subsample\", 0.5, 1.0),\n",
    "        \"model__estimator__colsample_bytree\": trial.suggest_float(\"model__estimator__colsample_bytree\", 0.1, 0.6),\n",
    "        \"model__estimator__gamma\": trial.suggest_float(\"model__estimator__gamma\", 0.0, 1.0),\n",
    "        \"model__estimator__reg_alpha\": trial.suggest_float(\"model__estimator__reg_alpha\", 0.0, 1.0),\n",
    "    }\n",
    "    pipe = Pipeline([\n",
    "        (\"transformation\", transform),\n",
    "        (\"model\", OneVsRestClassifier(XGBClassifier()))\n",
    "    ])\n",
    "    pipe.set_params(**params)\n",
    "\n",
    "\n",
    "    f1_scores = []\n",
    "\n",
    "    for X_train_index, X_test_index in tqdm(loo.split(X_train), total=len(X_train)):\n",
    "        X_train_loo, X_test_loo = X_train.iloc[X_train_index], X_train.iloc[X_test_index]\n",
    "        y_train_loo, y_test_loo = y_train.iloc[X_train_index], y_train.iloc[X_test_index]\n",
    "        pipe.fit(X_train_loo, y_train_loo)\n",
    "        y_pred=pipe.predict(X_test_loo)\n",
    "        f1 = f1_score(y_test_loo, y_pred, average='weighted', zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "    return sum(f1_scores)/ len(f1_scores)\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"maximize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=1)\n",
    "best_xgb = study_xgb.best_params\n",
    "print(f\"Лучшие параметры XGBoost: {best_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(mlflow_obj, y_true, y_prediction, y_probabilities, suffix_str, class_labels):\n",
    "    accuracy = accuracy_score(y_true, y_prediction)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_prediction, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_prediction, average='weighted', zero_division=0)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_prediction)\n",
    "\n",
    "    print(f\"Accuracy_{suffix_str}: {accuracy}\")\n",
    "    print(f\"Balanced Accuracy_{suffix_str}: {balanced_accuracy}\")\n",
    "    print(f\"Precision (Weighted)_{suffix_str}: {precision}\")\n",
    "    print(f\"Recall (Weighted)_{suffix_str}: {recall}\")\n",
    "    print(f\"F1 Score (Weighted)_{suffix_str}: {f1}\")\n",
    "    \n",
    "    mlflow_obj.log_metric(f\"accuracy_{suffix_str}\", accuracy)\n",
    "    mlflow_obj.log_metric(f\"balanced_accuracy_{suffix_str}\", balanced_accuracy)\n",
    "    mlflow_obj.log_metric(f\"precision_weighted_{suffix_str}\", precision)\n",
    "    mlflow_obj.log_metric(f\"recall_weighted_{suffix_str}\", recall)\n",
    "    mlflow_obj.log_metric(f\"f1_weighted_{suffix_str}\", f1)\n",
    "\n",
    "    try:\n",
    "        roc_auc_ovr_weighted = roc_auc_score(y_true, y_probabilities, multi_class='ovr', average='weighted')\n",
    "        print(f\"ROC AUC (OvR Weighted)_{suffix_str}: {roc_auc_ovr_weighted}\")\n",
    "        mlflow_obj.log_metric(f\"roc_auc_ovr_weighted_{suffix_str}\", roc_auc_ovr_weighted)\n",
    "\n",
    "        roc_auc_ovr_macro = roc_auc_score(y_true, y_probabilities, multi_class='ovr', average='macro')\n",
    "        print(f\"ROC AUC (OvR Macro)_{suffix_str}: {roc_auc_ovr_macro}\")\n",
    "        mlflow_obj.log_metric(f\"roc_auc_ovr_macro_{suffix_str}\", roc_auc_ovr_macro)\n",
    "    except ValueError as e:\n",
    "        print(f\"Не удалось рассчитать ROC AUC: {e}\")\n",
    "        mlflow_obj.log_metric(f\"roc_auc_ovr_weighted_{suffix_str}\", 0.0)\n",
    "        mlflow_obj.log_metric(f\"roc_auc_ovr_macro_{suffix_str}\", 0.0)\n",
    "\n",
    "    print(f\"Confusion Matrix_{suffix_str}:\\n\", cm)\n",
    "    mlflow_obj.log_text(f\"Confusion Matrix (text):\\n{cm}\", f\"confusion_matrix_text_{suffix_str}.txt\")\n",
    "    \n",
    "    cm_for_plot = confusion_matrix(y_true, y_prediction, labels=range(len(class_labels)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_for_plot, display_labels=class_labels)\n",
    "    fig_cm_width = max(8, len(class_labels) * 0.9)\n",
    "    fig_cm_height = max(6, len(class_labels) * 0.7)\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(fig_cm_width, fig_cm_height))\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax_cm, xticks_rotation='vertical')\n",
    "    ax_cm.set_title(f\"Общая матрица ошибок ({suffix_str})\")\n",
    "    plt.tight_layout()\n",
    "    mlflow_obj.log_figure(fig_cm, f\"confusion_matrix_overall_{suffix_str}.png\")\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    n_classes = y_probabilities.shape[1]\n",
    "    y_true_binarized = label_binarize(y_true, classes=range(n_classes))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc_individual = dict()\n",
    "    fig_roc, ax_roc = plt.subplots(figsize=(12, 10))\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_probabilities[:, i])\n",
    "        roc_auc_individual[i] = auc(fpr[i], tpr[i])\n",
    "        ax_roc.plot(fpr[i], tpr[i], lw=2, label=f'ROC класс {class_labels[i]} (AUC = {roc_auc_individual[i]:.2f})')\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_binarized.ravel(), y_probabilities.ravel())\n",
    "    roc_auc_individual[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    ax_roc.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                label=f'Micro-средняя ROC (AUC = {roc_auc_individual[\"micro\"]:.2f})',\n",
    "                color='deeppink', linestyle=':', linewidth=4)\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc_individual[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    ax_roc.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                label=f'Macro-средняя ROC (AUC = {roc_auc_individual[\"macro\"]:.2f})',\n",
    "                color='navy', linestyle=':', linewidth=4)\n",
    "    ax_roc.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', label='Случайное предсказание')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.set_title(f'ROC-кривые One-vs-Rest с усреднением ({suffix_str})')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    ax_roc.grid(True)\n",
    "    plt.tight_layout()\n",
    "    mlflow_obj.log_figure(fig_roc, f\"roc_curves_ovr_averages_{suffix_str}.png\")\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "def mlflow_run(model_type_name, pipeline_obj, params_dict, X_data_test, y_data_test, fitted_label_encoder):\n",
    "    mlflow.log_params(params_dict)\n",
    "    predict_start_time = time.time()\n",
    "    y_predicted_values = pipeline_obj.predict(X_data_test)\n",
    "    y_probability_values = pipeline_obj.predict_proba(X_data_test)\n",
    "    predict_end_time = time.time()\n",
    "    prediction_duration = predict_end_time - predict_start_time\n",
    "    print(f\"Время предсказания на тестовом наборе ({model_type_name}): {prediction_duration:.4f} секунд\")\n",
    "    mlflow.log_metric(\"prediction_time_test_seconds\", prediction_duration)\n",
    "    report_metrics(mlflow, y_data_test, y_predicted_values, y_probability_values, \n",
    "                   f\"{model_type_name}_eval\", class_labels=fitted_label_encoder.classes_)\n",
    "    mlflow.sklearn.log_model(pipeline_obj, \"model_pipeline\")\n",
    "    model_step_in_pipeline = pipeline_obj.named_steps['model']\n",
    "    importances_values_array = None\n",
    "    if hasattr(model_step_in_pipeline, 'estimators_'): \n",
    "        if all(hasattr(est, 'feature_importances_') for est in model_step_in_pipeline.estimators_):\n",
    "            imp_sum_list = [est.feature_importances_ for est in model_step_in_pipeline.estimators_]\n",
    "            importances_values_array = pd.DataFrame(imp_sum_list).mean(axis=0).values\n",
    "    elif hasattr(model_step_in_pipeline, 'feature_importances_'): \n",
    "        importances_values_array = model_step_in_pipeline.feature_importances_\n",
    "    if importances_values_array is not None:\n",
    "        feature_names_list = pipeline_obj.named_steps['transformation'].get_feature_names_out()\n",
    "        feat_imp_df = pd.DataFrame({\n",
    "            'feature': feature_names_list,\n",
    "            'importance': importances_values_array\n",
    "        }).sort_values(by='importance', ascending=False)\n",
    "        feat_imp_df = feat_imp_df[feat_imp_df['importance'] > 0].head(40)\n",
    "        if not feat_imp_df.empty:\n",
    "            total_importance_sum = feat_imp_df['importance'].sum()\n",
    "            feat_imp_df['importance_fraction'] = feat_imp_df['importance'] / total_importance_sum if total_importance_sum > 0 else 0.0\n",
    "            fig_fi_width = 25\n",
    "            fig_fi_height = max(10, len(feat_imp_df) * 0.5) \n",
    "            fig_fi, ax_fi = plt.subplots(figsize=(fig_fi_width, fig_fi_height))\n",
    "            bars = ax_fi.barh(feat_imp_df['feature'], feat_imp_df['importance_fraction'], color='skyblue')\n",
    "            ax_fi.invert_yaxis()\n",
    "            ax_fi.set_title(f\"Важность признаков - {model_type_name}\")\n",
    "            ax_fi.set_xlabel(\"Важность (%)\")\n",
    "            ax_fi.set_ylabel(\"Признаки\")\n",
    "            ax_fi.xaxis.set_major_formatter(ticker.PercentFormatter(xmax=1.0))\n",
    "            for bar_obj in bars:\n",
    "                width_val = bar_obj.get_width()\n",
    "                label_txt = f\"{width_val:.1%}\"\n",
    "                ax_fi.text(width_val + 0.01, bar_obj.get_y() + bar_obj.get_height() / 2, label_txt, va='center')\n",
    "            plt.tight_layout()\n",
    "            mlflow.log_figure(fig_fi, f\"feature_importances_{model_type_name}.png\")\n",
    "            plt.close(fig_fi)\n",
    "            feat_imp_df.to_csv(f\"feature_importances_{model_type_name}.csv\", index=False)\n",
    "            mlflow.log_artifact(f\"feature_importances_{model_type_name}.csv\")\n",
    "        else:\n",
    "            print(f\"Не найдено признаков с важностью > 0 для {model_type_name}.\")\n",
    "    else:\n",
    "        print(f\"Не удалось получить важность признаков для {model_type_name}.\")\n",
    "    print(f\"Запуск для {model_type_name} завершен. Все результаты залогированы в MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение финальной модели XGBoost...\n",
      "Время обучения финальной модели XGBoost: 3.5567 секунд\n"
     ]
    }
   ],
   "source": [
    "pipe_xgb = Pipeline([\n",
    "    (\"transformation\", transform),\n",
    "    (\"model\", OneVsRestClassifier(XGBClassifier()))\n",
    "])\n",
    "if 'best_xgb' in locals() or 'best_xgb' in globals():\n",
    "    pipe_xgb.set_params(**best_xgb)\n",
    "else:\n",
    "    print(\"Переменная best_xgb не найдена. Модель XGBoost будет использовать параметры по умолчанию.\")\n",
    "\n",
    "print(\"Начинаем обучение финальной модели XGBoost...\")\n",
    "train_start_time_xgb = time.time()\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "train_end_time_xgb = time.time()\n",
    "final_training_time_xgb = train_end_time_xgb - train_start_time_xgb\n",
    "print(f\"Время обучения финальной модели XGBoost: {final_training_time_xgb:.4f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время предсказания на тестовом наборе (XGBoost): 0.0785 секунд\n",
      "Accuracy_XGBoost_eval: 0.13793103448275862\n",
      "Balanced Accuracy_XGBoost_eval: 0.08571428571428572\n",
      "Precision (Weighted)_XGBoost_eval: 0.09865900383141762\n",
      "Recall (Weighted)_XGBoost_eval: 0.13793103448275862\n",
      "F1 Score (Weighted)_XGBoost_eval: 0.11362889983579638\n",
      "ROC AUC (OvR Weighted)_XGBoost_eval: 0.5625767846457502\n",
      "ROC AUC (OvR Macro)_XGBoost_eval: 0.5773931161431161\n",
      "Confusion Matrix_XGBoost_eval:\n",
      " [[0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 3]\n",
      " [0 1 0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 1 1]\n",
      " [0 0 0 1 0 0 2 1]\n",
      " [1 0 0 1 0 0 2 1]\n",
      " [0 3 1 0 0 0 1 2]]\n",
      "Запуск для XGBoost завершен. Все результаты залогированы в MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"raw_data_analysis\")\n",
    "with mlflow.start_run(run_name=\"XGBoost_LOO_Optuna_Final\"):\n",
    "    mlflow.log_metric(\"final_model_training_time_seconds\", final_training_time_xgb)\n",
    "    params_to_log_xgb = best_xgb if 'best_xgb' in locals() or 'best_xgb' in globals() else {}\n",
    "    mlflow_run(\"XGBoost\", pipe_xgb, params_to_log_xgb, X_test, y_test, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logged_model = 'runs:/aa735d26384d4e20aa803b9cf235e64f/model_pipeline'\n",
    "\n",
    "# loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_uri = 'runs:/38064bcda94e4c9e9ffefacb80375816/model_pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# logged_model = 'runs:/38064bcda94e4c9e9ffefacb80375816/model_pipeline'\n",
    "\n",
    "# loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# import pandas as pd\n",
    "# loaded_model.predict(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 18:01:29,695] A new study created in memory with name: no-name-5723bc59-cdeb-4dbc-80d4-8ca20625f637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed36e36668434e4b880750e37ffeeee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 18:01:54,399] Trial 0 finished with value: 0.1810344827586207 and parameters: {'model__estimator__n_estimators': 120, 'model__estimator__max_depth': 8, 'model__estimator__learning_rate': 0.22489526269450463, 'model__estimator__num_leaves': 301, 'model__estimator__subsample': 0.7762744322949857, 'model__estimator__colsample_bytree': 0.6148306819842884, 'model__estimator__reg_alpha': 0.03389338861497715, 'model__estimator__reg_lambda': 0.9283311917025703}. Best is trial 0 with value: 0.1810344827586207.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08ae8550d90412b901fba6659de79e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 18:02:20,523] Trial 1 finished with value: 0.20689655172413793 and parameters: {'model__estimator__n_estimators': 181, 'model__estimator__max_depth': 12, 'model__estimator__learning_rate': 0.10771283412819901, 'model__estimator__num_leaves': 50, 'model__estimator__subsample': 0.7075364778592654, 'model__estimator__colsample_bytree': 0.9181113851771636, 'model__estimator__reg_alpha': 0.2147778090614838, 'model__estimator__reg_lambda': 0.8138733167481704}. Best is trial 1 with value: 0.20689655172413793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры LightGBM: {'model__estimator__n_estimators': 181, 'model__estimator__max_depth': 12, 'model__estimator__learning_rate': 0.10771283412819901, 'model__estimator__num_leaves': 50, 'model__estimator__subsample': 0.7075364778592654, 'model__estimator__colsample_bytree': 0.9181113851771636, 'model__estimator__reg_alpha': 0.2147778090614838, 'model__estimator__reg_lambda': 0.8138733167481704}\n"
     ]
    }
   ],
   "source": [
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        \"model__estimator__n_estimators\": trial.suggest_int(\"model__estimator__n_estimators\", 100, 200),\n",
    "        \"model__estimator__max_depth\": trial.suggest_int(\"model__estimator__max_depth\", 6, 12),\n",
    "        \"model__estimator__learning_rate\": trial.suggest_float(\"model__estimator__learning_rate\", 0.01, 0.3),\n",
    "        \"model__estimator__num_leaves\": trial.suggest_int(\"model__estimator__num_leaves\", 50, 1000),\n",
    "        \"model__estimator__subsample\": trial.suggest_float(\"model__estimator__subsample\", 0.6, 1.0),\n",
    "        \"model__estimator__colsample_bytree\": trial.suggest_float(\"model__estimator__colsample_bytree\", 0.6, 1.0),\n",
    "        \"model__estimator__reg_alpha\": trial.suggest_float(\"model__estimator__reg_alpha\", 0.0, 1.0),\n",
    "        \"model__estimator__reg_lambda\": trial.suggest_float(\"model__estimator__reg_lambda\", 0.0, 1.0),\n",
    "    }\n",
    "    pipe = Pipeline([\n",
    "        (\"transformation\", transform),\n",
    "        (\"model\", OneVsRestClassifier(LGBMClassifier(random_state=42, verbose=-1)))])\n",
    "    pipe.set_params(**params)\n",
    "\n",
    "    f1_scores = []\n",
    "    for X_train_index, X_test_index in tqdm(loo.split(X_train), total=len(X_train)):\n",
    "        X_train_loo, X_test_loo = X_train.iloc[X_train_index], X_train.iloc[X_test_index]\n",
    "        y_train_loo, y_test_loo = y_train.iloc[X_train_index], y_train.iloc[X_test_index]\n",
    "        pipe.fit(X_train_loo, y_train_loo)\n",
    "        y_pred=pipe.predict(X_test_loo)\n",
    "        f1 = f1_score(y_test_loo, y_pred, average='weighted', zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "    return sum(f1_scores)/ len(f1_scores)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction=\"maximize\")\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=2)\n",
    "best_lgbm = study_lgbm.best_params\n",
    "print(f\"Лучшие параметры LightGBM: {best_lgbm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение финальной модели LightGBM...\n",
      "Время обучения финальной модели LightGBM: 0.2506 секунд\n",
      "Время предсказания на тестовом наборе (LightGBM): 0.0420 секунд\n",
      "Accuracy_LightGBM_eval: 0.1724137931034483\n",
      "Balanced Accuracy_LightGBM_eval: 0.10357142857142856\n",
      "Precision (Weighted)_LightGBM_eval: 0.12988505747126436\n",
      "Recall (Weighted)_LightGBM_eval: 0.1724137931034483\n",
      "F1 Score (Weighted)_LightGBM_eval: 0.14788862253365298\n",
      "ROC AUC (OvR Weighted)_LightGBM_eval: 0.5252262679848886\n",
      "ROC AUC (OvR Macro)_LightGBM_eval: 0.5467082917082917\n",
      "Confusion Matrix_LightGBM_eval:\n",
      " [[0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 3]\n",
      " [0 1 0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0 2 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 1 0 1 0 0 0 2]\n",
      " [1 0 0 0 0 1 2 1]\n",
      " [0 3 0 0 0 0 1 3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 18:02:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск для LightGBM завершен. Все результаты залогированы в MLflow.\n",
      "🏃 View run LightGBM_LOO_Optuna_Final at: http://84.201.144.227:8000/#/experiments/1/runs/9b893b5b81524dd3b233c424d53545ff\n",
      "🧪 View experiment at: http://84.201.144.227:8000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "pipe_lgbm = Pipeline([\n",
    "    (\"transformation\", transform),\n",
    "    (\"model\", OneVsRestClassifier(LGBMClassifier(random_state=42)))\n",
    "])\n",
    "if 'best_lgbm' in locals() or 'best_lgbm' in globals():\n",
    "    pipe_lgbm.set_params(**best_lgbm)\n",
    "else:\n",
    "    print(\"Переменная best_lgbm не найдена. Модель LightGBM будет использовать параметры по умолчанию.\")\n",
    "\n",
    "print(\"Начинаем обучение финальной модели LightGBM...\")\n",
    "train_start_time_lgbm = time.time()\n",
    "pipe_lgbm.fit(X_train, y_train)\n",
    "train_end_time_lgbm = time.time()\n",
    "final_training_time_lgbm = train_end_time_lgbm - train_start_time_lgbm\n",
    "print(f\"Время обучения финальной модели LightGBM: {final_training_time_lgbm:.4f} секунд\")\n",
    "\n",
    "mlflow.set_experiment(\"raw_data_analysis\")\n",
    "with mlflow.start_run(run_name=\"LightGBM_LOO_Optuna_Final\"):\n",
    "    mlflow.log_metric(\"final_model_training_time_seconds\", final_training_time_lgbm)\n",
    "    params_to_log_lgbm = best_lgbm if 'best_lgbm' in locals() or 'best_lgbm' in globals() else {}\n",
    "    mlflow_run(\"LightGBM\", pipe_lgbm, params_to_log_lgbm, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время предсказания на тестовом наборе (LightGBM): 0.0460 секунд\n",
      "Accuracy_LightGBM_eval: 0.1724137931034483\n",
      "Balanced Accuracy_LightGBM_eval: 0.10357142857142856\n",
      "Precision (Weighted)_LightGBM_eval: 0.12988505747126436\n",
      "Recall (Weighted)_LightGBM_eval: 0.1724137931034483\n",
      "F1 Score (Weighted)_LightGBM_eval: 0.14788862253365298\n",
      "ROC AUC (OvR Weighted)_LightGBM_eval: 0.5252262679848886\n",
      "ROC AUC (OvR Macro)_LightGBM_eval: 0.5467082917082917\n",
      "Confusion Matrix_LightGBM_eval:\n",
      " [[0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 3]\n",
      " [0 1 0 1 0 0 1 0]\n",
      " [0 1 0 0 0 0 2 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [0 1 0 1 0 0 0 2]\n",
      " [1 0 0 0 0 1 2 1]\n",
      " [0 3 0 0 0 0 1 3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 18:02:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск для LightGBM завершен. Все результаты залогированы в MLflow.\n",
      "🏃 View run LightGBM_LOO_Optuna_Final at: http://84.201.144.227:8000/#/experiments/1/runs/0ae2f19a6b864eb2b3be54eaa189a987\n",
      "🧪 View experiment at: http://84.201.144.227:8000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"raw_data_analysis\")\n",
    "with mlflow.start_run(run_name=\"LightGBM_LOO_Optuna_Final\"):\n",
    "    mlflow.log_metric(\"final_model_training_time_seconds\", final_training_time_lgbm)\n",
    "    params_to_log_lgbm = best_lgbm if 'best_lgbm' in locals() or 'best_lgbm' in globals() else {}\n",
    "    mlflow_run(\"LightGBM\", pipe_lgbm, params_to_log_lgbm, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 18:02:37,315] A new study created in memory with name: no-name-d957e0f4-c4a1-4502-9d99-56174134b2c0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388a6732bf9427bbeef42da49d25840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-07-05 18:07:32,223] Trial 0 failed with parameters: {'model__estimator__iterations': 728, 'model__estimator__depth': 10, 'model__estimator__learning_rate': 0.21512682435436242, 'model__estimator__l2_leaf_reg': 6.210684702203773} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arutt\\AppData\\Local\\Temp\\ipykernel_3396\\3892305994.py\", line 18, in objective_cat\n",
      "    pipe.fit(X_train_loo, y_train_loo)\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-05 18:07:32,234] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(f1_scores)/ \u001b[38;5;28mlen\u001b[39m(f1_scores)\n\u001b[32m     24\u001b[39m study_cat = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mstudy_cat\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m best_cat = study_cat.best_params\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЛучшие параметры CatBoost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_cat\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mobjective_cat\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     16\u001b[39m X_train_loo, X_test_loo = X_train.iloc[X_train_index], X_train.iloc[X_test_index]\n\u001b[32m     17\u001b[39m y_train_loo, y_test_loo = y_train.iloc[X_train_index], y_train.iloc[X_test_index]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_loo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_loo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m y_pred=pipe.predict(X_test_loo)\n\u001b[32m     20\u001b[39m f1 = f1_score(y_test_loo, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m'\u001b[39m, zero_division=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    657\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    658\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    659\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    660\u001b[39m             all_params=params,\n\u001b[32m    661\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:376\u001b[39m, in \u001b[36mOneVsRestClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    372\u001b[39m columns = (col.toarray().ravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y.T)\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\sklearn\\multiclass.py:96\u001b[39m, in \u001b[36m_fit_binary\u001b[39m\u001b[34m(estimator, X, y, fit_params, classes)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     95\u001b[39m     estimator = clone(estimator)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arutt\\Desktop\\ProjectClass\\.venv\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        \"model__estimator__iterations\": trial.suggest_int(\"model__estimator__iterations\", 300, 1000),\n",
    "        \"model__estimator__depth\": trial.suggest_int(\"model__estimator__depth\", 6, 10),\n",
    "        \"model__estimator__learning_rate\": trial.suggest_float(\"model__estimator__learning_rate\", 0.01, 0.3),\n",
    "        \"model__estimator__l2_leaf_reg\": trial.suggest_float(\"model__estimator__l2_leaf_reg\", 1.0, 10.0),\n",
    "    }\n",
    "    pipe = Pipeline([\n",
    "        (\"transformation\", transform),\n",
    "        (\"model\", OneVsRestClassifier(CatBoostClassifier(verbose=0)))\n",
    "    ])\n",
    "    pipe.set_params(**params)\n",
    "\n",
    "    f1_scores = []\n",
    "    for X_train_index, X_test_index in tqdm(loo.split(X_train), total=len(X_train)):\n",
    "        X_train_loo, X_test_loo = X_train.iloc[X_train_index], X_train.iloc[X_test_index]\n",
    "        y_train_loo, y_test_loo = y_train.iloc[X_train_index], y_train.iloc[X_test_index]\n",
    "        pipe.fit(X_train_loo, y_train_loo)\n",
    "        y_pred=pipe.predict(X_test_loo)\n",
    "        f1 = f1_score(y_test_loo, y_pred, average='weighted', zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "    return sum(f1_scores)/ len(f1_scores)\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"maximize\")\n",
    "study_cat.optimize(objective_cat, n_trials=2)\n",
    "best_cat = study_cat.best_params\n",
    "print(f\"Лучшие параметры CatBoost: {best_cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cat = Pipeline([\n",
    "    (\"transformation\", transform),\n",
    "    (\"model\", OneVsRestClassifier(CatBoostClassifier(verbose=0)))\n",
    "])\n",
    "if 'best_cat' in locals() or 'best_cat' in globals():\n",
    "    pipe_cat.set_params(**best_cat)\n",
    "else:\n",
    "    print(\"Переменная best_cat не найдена. Модель CatBoost будет использовать параметры по умолчанию.\")\n",
    "\n",
    "print(\"Начинаем обучение финальной модели CatBoost...\")\n",
    "train_start_time_cat = time.time()\n",
    "pipe_cat.fit(X_train, y_train)\n",
    "train_end_time_cat = time.time()\n",
    "final_training_time_cat = train_end_time_cat - train_start_time_cat\n",
    "print(f\"Время обучения финальной модели CatBoost: {final_training_time_cat:.4f} секунд\")\n",
    "\n",
    "mlflow.set_experiment(\"raw_data_analysis\")\n",
    "with mlflow.start_run(run_name=\"CatBoost_LOO_Optuna_Final\"):\n",
    "    mlflow.log_metric(\"final_model_training_time_seconds\", final_training_time_cat)\n",
    "    params_to_log_cat = best_cat if 'best_cat' in locals() or 'best_cat' in globals() else {}\n",
    "    mlflow_run(\"CatBoost\", pipe_cat, params_to_log_cat, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"raw_data_analysis\")\n",
    "with mlflow.start_run(run_name=\"CatBoost_LOO_Optuna_Final\"):\n",
    "    mlflow.log_metric(\"final_model_training_time_seconds\", final_training_time_cat)\n",
    "    params_to_log_cat = best_cat if 'best_cat' in locals() or 'best_cat' in globals() else {}\n",
    "    mlflow_run(\"CatBoost\", pipe_cat, params_to_log_cat, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_cat\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(conf_matrix, class_idx, y_true=None, y_scores=None, beta=0.5):\n",
    "    tp = conf_matrix[class_idx, class_idx]\n",
    "    fn = conf_matrix[class_idx, :].sum() - tp\n",
    "    fp = conf_matrix[:, class_idx].sum() - tp\n",
    "    tn = conf_matrix.sum() - (tp + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    f1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "    fbeta = (1 + beta**2) * precision * recall / (beta**2 * precision + recall) if (precision + recall) > 0 else 0\n",
    "    balanced_acc = (recall + specificity) / 2\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Confusion Matrix\": [[int(tp), int(fp)], [int(fn), int(tn)]],\n",
    "        \"Precision\": precision,\n",
    "        \"Recall (Sensitivity)\": recall,\n",
    "        \"Specificity\": specificity,\n",
    "        \"FPR\": fpr,\n",
    "        \"F1 Score\": f1,\n",
    "        f\"F{int(beta)} Score\": fbeta,\n",
    "        \"Balanced Accuracy\": balanced_acc,\n",
    "    }\n",
    "    if y_true is not None and y_scores is not None:\n",
    "        try:\n",
    "            metrics[\"ROC-AUC\"] = roc_auc_score(y_true, y_scores)\n",
    "            fpr_arr, tpr_arr, thresholds = roc_curve(y_true, y_scores)\n",
    "            metrics[\"ROC Curve\"] = {\n",
    "                \"FPR\": fpr_arr.tolist(),\n",
    "                \"TPR\": tpr_arr.tolist(),\n",
    "                \"Thresholds\": thresholds.tolist()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            metrics[\"ROC-AUC\"] = None\n",
    "            metrics[\"ROC Curve\"] = {\"error\": str(e)}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Overall Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    for class_idx in range(len(le.classes_)):\n",
    "        print(f\"Class {le.inverse_transform([class_idx])[0]} (label {class_idx}):\")\n",
    "\n",
    "        y_test_bin = (y_test == class_idx).astype(int)\n",
    "        y_pred_bin = (y_pred == class_idx).astype(int)\n",
    "\n",
    "        try:\n",
    "            if hasattr(model.named_steps[\"model\"], \"predict_proba\"):\n",
    "                y_scores = model.predict_proba(X_test)[:, class_idx]\n",
    "            else:\n",
    "                y_scores = y_pred_bin\n",
    "        except:\n",
    "            y_scores = y_pred_bin\n",
    "\n",
    "        metrics = calculate_metrics(conf_mat, class_idx, y_true=y_test_bin, y_scores=y_scores)\n",
    "        results[(model_name, class_idx)] = metrics\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, dict):\n",
    "                continue\n",
    "            print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Plotting One-vs-Rest ROC curves for model: {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if not hasattr(model.named_steps[\"model\"], \"predict_proba\"):\n",
    "        print(f\"Model {model_name} does not support probability predictions. Skipping ROC plots.\")\n",
    "        continue\n",
    "\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    n_classes = len(le.classes_)\n",
    "    y_test_bin = label_binarize(y_test, classes=list(range(n_classes)))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for class_idx in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_proba[:, class_idx])\n",
    "        auc_score = roc_auc_score(y_test_bin[:, class_idx], y_proba[:, class_idx])\n",
    "        class_label = le.inverse_transform([class_idx])[0]\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_label} vs Rest (AUC = {auc_score:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "    plt.title(f\"One-vs-Rest ROC Curves - {model_name}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, X_test, y_test, beta=2.0):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    conf = confusion_matrix(y_test, y_pred, labels=list(range(len(le.classes_))))\n",
    "    \n",
    "    metrics_list = []\n",
    "\n",
    "    for class_idx in range(len(le.classes_)):\n",
    "        bin_true = (y_test == class_idx).astype(int)\n",
    "        bin_score = y_proba[:, class_idx]\n",
    "\n",
    "        metrics = calculate_metrics(\n",
    "            conf_matrix=conf,\n",
    "            class_idx=class_idx,\n",
    "            y_true=bin_true,\n",
    "            y_scores=bin_score,\n",
    "            beta=beta\n",
    "        )\n",
    "        metrics[\"Model\"] = model_name\n",
    "        metrics[\"Class\"] = le.inverse_transform([class_idx])[0]\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    return pd.DataFrame(metrics_list)\n",
    "\n",
    "all_metrics = pd.concat([\n",
    "    evaluate_model(model, name, X_test, y_test)\n",
    "    for name, model in models.items()\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "cols = [\"Model\", \"Class\", \"Accuracy\", \"Precision\", \"Recall (Sensitivity)\", \"Specificity\",\n",
    "        \"FPR\", \"F1 Score\", \"F2 Score\", \"Balanced Accuracy\", \"ROC-AUC\"]\n",
    "all_metrics = all_metrics[cols]\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "display(all_metrics.sort_values(by=[\"Model\", \"Class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_confusion_matrix(model, model_name, X_test, y_test, class_labels):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=range(len(class_labels)))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.title(f'Overall Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_binary_confusion_matrix(model, model_name, X_test, y_test, class_idx, class_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    bin_true = (y_test == class_idx).astype(int)\n",
    "    bin_pred = (y_pred == class_idx).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(bin_true, bin_pred)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Oranges\", cbar=False,\n",
    "                xticklabels=[\"Not \" + class_name, class_name],\n",
    "                yticklabels=[\"Not \" + class_name, class_name])\n",
    "    plt.title(f'Binary Confusion Matrix - {model_name} - Class: {class_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"🔷 {model_name}\")\n",
    "    plot_overall_confusion_matrix(model, model_name, X_test, y_test, le.classes_)\n",
    "\n",
    "    for class_idx, class_name in enumerate(le.classes_):\n",
    "        plot_binary_confusion_matrix(model, model_name, X_test, y_test, class_idx, str(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_pr_curves(model_pipeline, X_data_test, y_data_test, model_type_name, fitted_label_encoder):\n",
    "    y_score_probabilities = model_pipeline.predict_proba(X_data_test)\n",
    "    n_model_classes = len(fitted_label_encoder.classes_)\n",
    "    y_data_test_binarized = label_binarize(y_data_test, classes=range(n_model_classes))\n",
    "    class_name_labels = fitted_label_encoder.classes_\n",
    "    fpr_dict = dict()\n",
    "    tpr_dict = dict()\n",
    "    roc_auc_values_dict = dict()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for i in range(n_model_classes):\n",
    "        fpr_dict[i], tpr_dict[i], _ = roc_curve(y_data_test_binarized[:, i], y_score_probabilities[:, i])\n",
    "        roc_auc_values_dict[i] = auc(fpr_dict[i], tpr_dict[i])\n",
    "        plt.plot(fpr_dict[i], tpr_dict[i], lw=2, label=f'ROC класс {class_name_labels[i]} (AUC = {roc_auc_values_dict[i]:.2f})')\n",
    "    fpr_dict[\"micro\"], tpr_dict[\"micro\"], _ = roc_curve(y_data_test_binarized.ravel(), y_score_probabilities.ravel())\n",
    "    roc_auc_values_dict[\"micro\"] = auc(fpr_dict[\"micro\"], tpr_dict[\"micro\"])\n",
    "    plt.plot(fpr_dict[\"micro\"], tpr_dict[\"micro\"],\n",
    "             label=f'Micro-средняя ROC (AUC = {roc_auc_values_dict[\"micro\"]:.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "    all_unique_fpr = np.unique(np.concatenate([fpr_dict[i] for i in range(n_model_classes)]))\n",
    "    mean_calculated_tpr = np.zeros_like(all_unique_fpr)\n",
    "    for i in range(n_model_classes):\n",
    "        mean_calculated_tpr += np.interp(all_unique_fpr, fpr_dict[i], tpr_dict[i])\n",
    "    mean_calculated_tpr /= n_model_classes\n",
    "    fpr_dict[\"macro\"] = all_unique_fpr\n",
    "    tpr_dict[\"macro\"] = mean_calculated_tpr\n",
    "    roc_auc_values_dict[\"macro\"] = auc(fpr_dict[\"macro\"], tpr_dict[\"macro\"])\n",
    "    plt.plot(fpr_dict[\"macro\"], tpr_dict[\"macro\"],\n",
    "             label=f'Macro-средняя ROC (AUC = {roc_auc_values_dict[\"macro\"]:.2f})',\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Случайное предсказание')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC-кривая с усреднением - {model_type_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(n_model_classes):\n",
    "        precision_values, recall_values, _ = precision_recall_curve(y_data_test_binarized[:, i], y_score_probabilities[:, i])\n",
    "        avg_precision = auc(recall_values, precision_values)\n",
    "        plt.plot(recall_values, precision_values, lw=2, label=f'PR класс {class_name_labels[i]} (AP = {avg_precision:.2f})')\n",
    "    plt.xlabel(\"Recall (Полнота)\")\n",
    "    plt.ylabel(\"Precision (Точность)\")\n",
    "    plt.title(f\"Precision-Recall кривая - {model_type_name}\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Построение ROC и PR кривых для XGBoost (отдельно) ---\")\n",
    "if 'pipe_xgb' in locals() and hasattr(pipe_xgb, \"predict_proba\"):\n",
    "    plot_roc_pr_curves(pipe_xgb, X_test, y_test, \"XGBoost\", le)\n",
    "else:\n",
    "    print(\"Модель pipe_xgb не обучена или недоступна.\")\n",
    "\n",
    "print(\"\\n--- Построение ROC и PR кривых для LightGBM (отдельно) ---\")\n",
    "if 'pipe_lgbm' in locals() and hasattr(pipe_lgbm, \"predict_proba\"):\n",
    "    plot_roc_pr_curves(pipe_lgbm, X_test, y_test, \"LightGBM\", le)\n",
    "else:\n",
    "    print(\"Модель pipe_lgbm не обучена или недоступна.\")\n",
    "\n",
    "print(\"\\n--- Построение ROC и PR кривых для CatBoost (отдельно) ---\")\n",
    "if 'pipe_cat' in locals() and hasattr(pipe_cat, \"predict_proba\"):\n",
    "    plot_roc_pr_curves(pipe_cat, X_test, y_test, \"CatBoost\", le)\n",
    "else:\n",
    "    print(\"Модель pipe_cat не обучена или недоступна.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/70d3629b68cc4109bb3f37a47ce4f1df/model_pipeline'\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(loaded_model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
