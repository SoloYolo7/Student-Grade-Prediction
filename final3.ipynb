{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f1082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder, OneHotEncoder, LabelEncoder, label_binarize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e62a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = 42\n",
    "N_SPLITS = 5\n",
    "N_TRIALS_XGB = 10\n",
    "N_TRIALS_LGBM = 12\n",
    "N_TRIALS_CAT = 10\n",
    "EARLY_STOP = 50\n",
    "EXPERIMENT_NAME = \"raw_data_analysis\"\n",
    "CACHE_DIR = \"cache_ml\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80aa422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://tigran1/artifacts/1', creation_time=1750530849025, experiment_id='1', last_update_time=1750530849025, lifecycle_stage='active', name='raw_data_analysis', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://84.201.144.227:8000\")\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae0ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/student.csv\").drop(columns=[\"number\", \"Id\"], errors=\"ignore\")\n",
    "\n",
    "# Attendance: приводим к числу; \"3\" -> 3; всё остальное аккуратно в NaN, потом имьютация в числовом пайпе\n",
    "df[\"Attendance\"] = (\n",
    "    df[\"Attendance\"]\n",
    "    .replace({\"Always\": 3, \"Sometimes\": 2, \"Never\": 1})\n",
    "    .pipe(pd.to_numeric, errors=\"coerce\")\n",
    ")\n",
    "\n",
    "# Scholarship: \"0%\" -> 0 и т.д.\n",
    "if \"Scholarship\" in df.columns:\n",
    "    df[\"Scholarship\"] = df[\"Scholarship\"].fillna(\"0%\").astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "    df[\"Scholarship\"] = pd.to_numeric(df[\"Scholarship\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Grade -> целевую в 0..8\n",
    "grade_mapping = {\"Fail\": 0, \"FD\": 1, \"DD\": 2, \"DC\": 3, \"CC\": 4, \"CB\": 5, \"BB\": 6, \"BA\": 7, \"AA\": 8}\n",
    "df[\"Grade\"] = df[\"Grade\"].map(grade_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eb3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Grade\"])\n",
    "y = df[\"Grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3647cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = pd.Series(le.fit_transform(y), index=y.index)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=RNG, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d16cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9731ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_all = X.select_dtypes(include=\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a468114",
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_ohe = [c for c in [\"Sex\", \"High_School_Type\", \"Transportation\"] if c in X.columns]\n",
    "ord_list = [c for c in cat_cols_all if c not in explicit_ohe]\n",
    "num_list = X.select_dtypes(exclude=\"object\").columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b5cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "    # Для совместимости используем sparse=False (в новых версиях упадёт варнинг – он заглушён)\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "    (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"power\", PowerTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2b20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ColumnTransformer([\n",
    "    (\"ord_pipe\", ord_pipe, ord_list),\n",
    "    (\"num_pipe\", num_pipe, num_list),\n",
    "    (\"ohe_pipe\", ohe_pipe, explicit_ohe),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0750e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = joblib.Memory(location=CACHE_DIR, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "107145f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fit_transform(X_tr, X_val, transformer):\n",
    "    \"\"\"Фитим трансформер на train, применяем на train/val (для ранней остановки в тюнинге).\"\"\"\n",
    "    Xt_tr = transformer.fit_transform(X_tr)\n",
    "    Xt_val = transformer.transform(X_val)\n",
    "    return Xt_tr, Xt_val, transformer\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "@dataclass\n",
    "class TuneResult:\n",
    "    best_params: dict\n",
    "    best_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "968e2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgb(X_tr, y_tr, transformer, n_classes) -> TuneResult:\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RNG)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 10.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 2.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 2.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 2.0),\n",
    "        }\n",
    "        f1_scores = []\n",
    "        for tr_idx, val_idx in skf.split(X_tr, y_tr):\n",
    "            X_tr_f, X_val_f = X_tr.iloc[tr_idx], X_tr.iloc[val_idx]\n",
    "            y_tr_f, y_val_f = y_tr.iloc[tr_idx], y_tr.iloc[val_idx]\n",
    "\n",
    "            # Трансформируем вручную (чтобы пробросить eval_set уже в преобразованном виде)\n",
    "            trf = clone(transformer)\n",
    "            Xt_tr_f, Xt_val_f, _ = transform_fit_transform(X_tr_f, X_val_f, trf)\n",
    "\n",
    "            clf = XGBClassifier(\n",
    "                objective=\"multi:softprob\",\n",
    "                num_class=n_classes,\n",
    "                random_state=RNG,\n",
    "                n_jobs=-1,\n",
    "                tree_method=\"hist\",\n",
    "                eval_metric=\"mlogloss\",\n",
    "                **params\n",
    "            )\n",
    "            clf.fit(\n",
    "                Xt_tr_f, y_tr_f,\n",
    "                eval_set=[(Xt_val_f, y_val_f)],\n",
    "                early_stopping_rounds=EARLY_STOP,\n",
    "                verbose=False\n",
    "            )\n",
    "            y_pred_f = clf.predict(Xt_val_f)\n",
    "            f1_scores.append(macro_f1(y_val_f, y_pred_f))\n",
    "        return float(np.mean(f1_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RNG),\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS_XGB, show_progress_bar=False)\n",
    "    return TuneResult(study.best_params, study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f34f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(X_tr, y_tr, transformer) -> TuneResult:\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RNG)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1800),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", -1, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 256),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 2.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 2.0),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "            \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 1.0),\n",
    "        }\n",
    "        f1_scores = []\n",
    "        for tr_idx, val_idx in skf.split(X_tr, y_tr):\n",
    "            X_tr_f, X_val_f = X_tr.iloc[tr_idx], X_tr.iloc[val_idx]\n",
    "            y_tr_f, y_val_f = y_tr.iloc[tr_idx], y_tr.iloc[val_idx]\n",
    "\n",
    "            trf = clone(transformer)\n",
    "            Xt_tr_f, Xt_val_f, _ = transform_fit_transform(X_tr_f, X_val_f, trf)\n",
    "\n",
    "            clf = LGBMClassifier(\n",
    "                objective=\"multiclass\",\n",
    "                random_state=RNG,\n",
    "                n_jobs=-1,\n",
    "                **params\n",
    "            )\n",
    "            clf.fit(\n",
    "                Xt_tr_f, y_tr_f,\n",
    "                eval_set=[(Xt_val_f, y_val_f)],\n",
    "                eval_metric=\"multi_logloss\",\n",
    "                early_stopping_rounds=EARLY_STOP,\n",
    "                verbose=False\n",
    "            )\n",
    "            y_pred_f = clf.predict(Xt_val_f)\n",
    "            f1_scores.append(macro_f1(y_val_f, y_pred_f))\n",
    "        return float(np.mean(f1_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RNG),\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS_LGBM, show_progress_bar=False)\n",
    "    return TuneResult(study.best_params, study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0482cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_cat(X_tr, y_tr, transformer) -> TuneResult:\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RNG)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 400, 1500),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 0.0, 2.0),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 2.0),\n",
    "        }\n",
    "        f1_scores = []\n",
    "        for tr_idx, val_idx in skf.split(X_tr, y_tr):\n",
    "            X_tr_f, X_val_f = X_tr.iloc[tr_idx], X_tr.iloc[val_idx]\n",
    "            y_tr_f, y_val_f = y_tr.iloc[tr_idx], y_tr.iloc[val_idx]\n",
    "\n",
    "            trf = clone(transformer)\n",
    "            Xt_tr_f, Xt_val_f, _ = transform_fit_transform(X_tr_f, X_val_f, trf)\n",
    "\n",
    "            clf = CatBoostClassifier(\n",
    "                loss_function=\"MultiClass\",\n",
    "                random_seed=RNG,\n",
    "                thread_count=-1,\n",
    "                verbose=False,\n",
    "                **params\n",
    "            )\n",
    "            clf.fit(\n",
    "                Xt_tr_f, y_tr_f,\n",
    "                eval_set=(Xt_val_f, y_val_f),\n",
    "                use_best_model=True,\n",
    "                early_stopping_rounds=EARLY_STOP,\n",
    "                verbose=False\n",
    "            )\n",
    "            y_pred_f = clf.predict(Xt_val_f)\n",
    "            # Cat возвращает shape (n,1); приведём\n",
    "            y_pred_f = y_pred_f.reshape(-1).astype(int)\n",
    "            f1_scores.append(macro_f1(y_val_f, y_pred_f))\n",
    "        return float(np.mean(f1_scores))\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RNG),\n",
    "                                pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS_CAT, show_progress_bar=False)\n",
    "    return TuneResult(study.best_params, study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee93cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(estimator):\n",
    "    return Pipeline(\n",
    "        steps=[(\"transform\", transform), (\"model\", estimator)],\n",
    "        memory=memory\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef5e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
